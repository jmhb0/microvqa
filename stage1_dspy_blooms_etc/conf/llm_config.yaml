default:
  model_type: 'chat'
  temperature: 0.7
  max_tokens: 2048
  cache: True